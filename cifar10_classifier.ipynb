{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHh3t5PoiTYw"
      },
      "outputs": [],
      "source": [
        "# import  Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "# import torchvision\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The dataset we'll be using `CIFAR10`"
      ],
      "metadata": {
        "id": "DElVbhGXigMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup train data\n",
        "\n",
        "train_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "2Kc76EUxigVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "id": "-Ep8g5H2igYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image,label"
      ],
      "metadata": {
        "collapsed": true,
        "id": "piCWwL5wigbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_names = train_data.classes\n",
        "classes_names"
      ],
      "metadata": {
        "id": "6XPjtvDpigde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "k35I7ITiiggW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xoCUwMQXigjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape , label"
      ],
      "metadata": {
        "id": "F6VwvXizigmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image,label = train_data[0]\n",
        "print(f\"image shape: {image}\")\n",
        "image = image.permute(1,2,0)\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "chyPT33TigpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4,4\n",
        "for i in range(1,rows* cols +1):\n",
        "  random_idx = torch.randint(0,len(train_data), size=[1]).item()\n",
        "  img,label = train_data[random_idx]\n",
        "  img = img.permute(1,2,0)\n",
        "  fig.add_subplot(rows,cols,i)\n",
        "  plt.imshow(img.squeeze())\n",
        "  plt.title(classes_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "G-zZslXVigs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "jL4R9N1uigwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing DataLoader\n",
        "\n",
        "Right now , our data is in the form of 'Datasets'.\n",
        "\n",
        "Using \"DataLoader\" will let us use the data as python iterable"
      ],
      "metadata": {
        "id": "mNcxMhg3oOGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#setting up the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into Iterables\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)"
      ],
      "metadata": {
        "id": "Szi23CDloOJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking out the shape of training dataloader\n",
        "train_features_batch , train_label_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape,train_label_batch.shape"
      ],
      "metadata": {
        "id": "0IDO5vazoOMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img,label = train_features_batch[random_idx], train_label_batch[random_idx]\n",
        "img = img.permute(1,2,0)\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(classes_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "kL9EOA1XoOPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a base-line model"
      ],
      "metadata": {
        "id": "6YcMgP6ooOSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# getting a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# flatten the sample\n",
        "output = flatten_model(x)\n",
        "\n",
        "x.shape, output.shape"
      ],
      "metadata": {
        "id": "R6dbjKJloOVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "X1OOpF0LAch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using first linear model\n",
        "from torch import nn\n",
        "class CIFAR10MODEL_0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,out_features=output_shape)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "# determining input parameters\n",
        "model_0 = CIFAR10MODEL_0(\n",
        "    input_shape=1024,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(classes_names)\n",
        ").to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "7LxLmPXooOX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup loss , optimizer & evalutation metrics\n",
        "\n",
        "* loss function -> for Multi-Class classification , we use  `torch.nn.CrossEntropyLoss`\n",
        "* Optimizer -> We can use SGD or Adam( for this project we are going to use `SGD`)\n",
        "* Evaluation metrics -> Custom made accuracy funciton"
      ],
      "metadata": {
        "id": "hiy6wIrLA3T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(params= model_0.parameters(),\n",
        "                            lr = 0.1)\n",
        "\n",
        "# accuracy function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) *100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "Mxt9g8y5oOal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a training loop & training a model using batch data"
      ],
      "metadata": {
        "id": "w1bTpmnXoOdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training & testing\n",
        "\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "F4lxSt0-oOf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL1Q0lfGtQOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmUSr2q1tQRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BWjOhVatQUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haB0Wqt7tQXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSvLcjzItQaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfeUE4IetQc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-calyp4tQfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Igm9sjaQtQk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEou_DKUtQoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9x6DTr54tQq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZUGdYfloOjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1eNi4-PoOmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}